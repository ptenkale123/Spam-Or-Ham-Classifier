{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom math import log, sqrt\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read data from the .csv file\nmessages = pd.read_csv('../input/spam-or-ham/spam.csv', encoding = 'latin-1')\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get rid of the unnecessary columns in the data frame\nmessages.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n# rename columns\nmessages.rename(columns = {'v1': 'labels', 'v2': 'text'}, inplace = True)\n\n# creates a new index/column with new labels for each type\nmessages['label'] = messages['labels'].map({'ham': 0, 'spam': 1})\n# drop original labels column\nmessages.drop(['labels'], axis = 1, inplace = True)\n\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffle the data so you can train \nmessages = messages.sample(frac=1).reset_index(drop=True)\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create corresponding wordcloud image for spam dataset to get an idea of most frequently used words\nallSpamMessagesStr = ' '.join(list(messages[messages['label'] == 1]['text']))\nspamWc = WordCloud(width = 512, height = 512).generate(allSpamMessagesStr)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(spamWc)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create corresponding wordcloud image for ham dataset to get an idea of most frequently used words\nallHamMessagesStr = ' '.join(list(messages[messages['label'] == 0]['text']))\nhamWc = WordCloud(width = 512, height = 512).generate(allHamMessagesStr)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(hamWc)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenizeMessage(message):\n    tokenized = word_tokenize(message.lower())\n    stopWords = stopwords.words('english')\n    tokenized = [w for w in tokenized if not w in stopWords]\n    porterStemmer = PorterStemmer()\n    tokenized = [porterStemmer.stem(w) for w in tokenized]\n    return tokenized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# collect TF-IDF data\nnumMessages = int(messages['text'].size * 0.75)\nnumSpamMessages, numHamMessages = 0, 0\ntfSpam = dict() # term frequency of each item in spam dataset\ntfHam = dict() # term frequency of each item in ham dataset\noccurencesSpam = dict() # calculates total # of messages containing 'word' in spam dataset\noccurencesHam = dict() # calculates total # of messages containing 'word' in ham dataset\nfor i in range(numMessages):\n    # incremenet\n    if (messages['label'][i] == 1):\n        numSpamMessages += 1\n    else:\n        numHamMessages += 1\n    tokenizedMessage = tokenizeMessage(messages['text'][i])\n    vocabulary = set()\n    for word in tokenizedMessage:\n        if (messages['label'][i] == 1):\n            tfSpam[word] = tfSpam.get(word, 0) + 1\n        else:\n            tfHam[word] = tfHam.get(word, 0) + 1\n        if word not in vocabulary:\n            vocabulary.add(word)\n    for word in vocabulary:\n        if (messages['label'][i] == 1):\n            occurencesSpam[word] = occurencesSpam.get(word, 0) + 1\n        else:\n            occurencesHam[word] = occurencesHam.get(word, 0) + 1\n\n# calculate IDF using the occurences dictionary\nidfSpam = dict()\nidfHam = dict()\nfor word in occurencesSpam:\n    idfSpam[word] = log(numSpamMessages / occurencesSpam[word])\nfor word in occurencesHam:\n    idfHam[word] = log(numHamMessages / occurencesHam[word])\n    \n# calculate P(w | spam) and P(w | ham) for words that were found in those corresponding datasets\npWordSpam = dict()\npWordHam = dict()\ntfIdfSumSpam = 0\ntfIdfSumHam = 0\n# set pWord originally equal to just the TF-IDF score and keep track of sum of T\nfor word in idfSpam:\n    pWordSpam[word] = tfSpam[word] * idfSpam[word]\n    tfIdfSumSpam += pWordSpam[word]\nfor word in idfHam:\n    pWordHam[word] = tfHam[word] * idfHam[word]\n    tfIdfSumHam += pWordHam[word]\n\n# modify pWord so that it's (TF-IDF + 1)/()\nfor word in idfSpam:\n    pWordSpam[word] = (pWordSpam[word] + 1) / (tfIdfSumSpam + numSpamMessages)\nfor word in idfHam:\n    pWordHam[word] = (pWordHam[word] + 1) / (tfIdfSumHam + numHamMessages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify(message):\n    # use log() for everything cause if you multiply a bunch of fractions python won't be able to represent the number w enough precision\n    # if a > b, log(a) > log(b)\n    # You don't need to know exact probability, we just need to know which value is greater so we can just compare the log values of each\n    tokenizedMessage = tokenizeMessage(message)\n    pSpam, pHam = 0, 0\n    for word in tokenizedMessage:\n        if word in idfSpam:\n            pSpam += log(pWordSpam[word])\n        else:\n            # if TF(w | spam) = 0, numerator is 1\n            pSpam -= log(tfIdfSumSpam + numSpamMessages)\n        if word in idfHam:\n            pHam += log(pWordHam[word])\n        else:\n            # if TF(w | ham) = 0, numerator of  1\n            pHam -= log(tfIdfSumHam + numHamMessages)\n            \n    # incorporate P(spam) and P(ham) with messages \n    pSpam += log(numSpamMessages / numMessages)\n    pHam += log(numHamMessages / numMessages)\n    \n    # ignore denominator in Naive Bayes cause it's going to be\n    return pSpam >= pHam\n\nnumTruePos, numFalsePos = 0, 0\nnumTrueNeg, numFalseNeg = 0, 0\nnumTotal = 0\n\n# go through rest of dataset to check accuracy on un-trained examples\nfor i in range(numMessages, messages['text'].size):\n    classification = classify(messages['text'][i])\n    if (classification == 0 and messages['label'][i] == 0):\n        numTrueNeg += 1\n    if (classification == 0 and messages['label'][i] == 1):\n        numFalseNeg += 1\n    if (classification == 1 and messages['label'][i] == 0):\n        numFalsePos += 1\n    if (classification == 1 and messages['label'][i] == 1):\n        numTruePos += 1\n    numTotal += 1\n\n# calculate metrics on performance of the algorithm \n# use numbers based on true positives, false positives, false negatives, \nprecision = numTruePos / (numTruePos + numFalsePos)\nrecall = numTruePos / (numTruePos + numFalseNeg)\nf1Score = 2 * (precision * recall) / (precision + recall)\naccuracy = (numTruePos + numTrueNeg) / numTotal\nprint('Precision: ', precision)\nprint('Recall: ', recall)\nprint('FScore: ', f1Score)\nprint('Accuracy: ', accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Non-test set example (Ham)\nclassify('Thank you for that present Joe, it means the world to me')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another non-test set example (Ham)\nclassify('Are you free right now? I see you near the porch below')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try a spam message\nclassify('Congratzz!! click the link to get your free iPhone today!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}